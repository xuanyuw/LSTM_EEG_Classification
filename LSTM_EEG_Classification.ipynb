{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of actual analysis\n",
    "\n",
    "Previous Paper: https://pubmed.ncbi.nlm.nih.gov/30334800/ \n",
    "\n",
    "used similar dataset, LSTM + 1d-AX + softmax\n",
    "\n",
    "1d-AX: kinda like windowed mean in A2\n",
    "\n",
    "\n",
    "\n",
    "Hybrid NN in time domain: https://www.biorxiv.org/content/10.1101/2020.09.20.305300v1.full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import biosig\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz \n",
    "\n",
    "\n",
    "import scipy.io\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Conv1D\n",
    "from keras.optimizers import SGD, Nadam, Adam, RMSprop\n",
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "from mne import create_info\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables here\n",
    "#Xuanyu\n",
    "data_path = './BCICIV_2b_gdf/'#the folder where all raw data files live\n",
    "\n",
    "#Can\n",
    "#data_path = '/Users/canliu/COGS 189/Project'\n",
    "\n",
    "train_portion = 0.7 #the portion of training data among all the raw data files\n",
    "\n",
    "# from the data description document\n",
    "event_start = 4 #the start time point (sec) of imagery for each trial\n",
    "event_end = 7 #the end time point (sec) of imagery for each trial\n",
    "bsl_start = 0 #the start time point (sec) of baseline for each trial\n",
    "bsl_end = 2 #the end time point (sec) of baseline for each trial\n",
    "\n",
    "files = [os.path.join(data_path, f) for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "train_files = sorted([f for f in files if f[-7:-4] in ['01T', '02T']])\n",
    "# for testing purposes only\n",
    "#train_files = files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_ind_conversion(sr, t):\n",
    "    \"\"\"\n",
    "    Convert time in second to the index in the signal array\n",
    "    \"\"\"\n",
    "    return int(np.round(sr*t))\n",
    "\n",
    "\n",
    "# from A1\n",
    "def butter_bandpass(lowcut, highcut, fs, order = 2):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        sos = butter(order, [low, high], analog = False, btype = 'band', output = 'sos')\n",
    "        return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order = 2):\n",
    "        sos = butter_bandpass(lowcut, highcut, fs, order = order)\n",
    "        y = sosfiltfilt(sos, data)\n",
    "        return y\n",
    "\n",
    "def populate_filt_data(files, event_start, event_end, bsl_start, bsl_end, lowcut=7, highcut=30):\n",
    "    \"\"\"\n",
    "    populate and pre-process data for training the model\n",
    "    \n",
    "    \"It is noted in the literature that while performing any motor imagery tasks, \n",
    "    two major frequency band of EEG spectrum i.e mu (7-12 Hz) as well as beta (12-30 Hz) \n",
    "    bands are actively involved.\"\n",
    "    \n",
    "    input:\n",
    "        files: list of file paths to the raw data files\n",
    "        event_start: the start time point (sec) of imagery for each trial\n",
    "        event_end: the end time point (sec) of imagery for each trial\n",
    "        bsl_start: the start time point (sec) of baseline for each trial\n",
    "        bsl_end: the end time point (sec) of baseline for each trial\n",
    "        lowcut: lower end of the bandpass filter, default=7Hz\n",
    "        highcut: higher end of the bandpass filter, default=30Hz\n",
    "        \n",
    "    output:\n",
    "        data: list of eeg signal segments for each imagery \n",
    "        label: list of labels for each segment\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    data = []\n",
    "    for i in files:\n",
    "        HDR = json.loads(biosig.header(i))\n",
    "        sr  = HDR['Samplingrate']\n",
    "        events = pd.json_normalize(HDR['EVENT'])\n",
    "        mi_events = events[events.Description.apply(lambda x: 'class' in x)]\n",
    "        all_data = biosig.data(i).T\n",
    "        \n",
    "        for j in mi_events.index:\n",
    "            t_start = time_ind_conversion(sr, events.POS[j-1]+event_start)\n",
    "            t_end = time_ind_conversion(sr, events.POS[j-1]+event_end)\n",
    "            #only use the EEG channels to prevent the model learning EOG patterns\n",
    "            seg = all_data[:3, t_start:t_end]\n",
    "            #calculate baseline and trial mean\n",
    "            t_bsl_start = time_ind_conversion(sr, events.POS[j-1]+bsl_start)\n",
    "            t_bsl_end = time_ind_conversion(sr, events.POS[j-1]+bsl_end)\n",
    "            bsl_sig = all_data[:3, t_bsl_start:t_bsl_end]\n",
    "            bsl = np.nanmean(bsl_sig, 1)\n",
    "            trial_mean = np.nanmean(seg, 1)\n",
    "            #preprocess the data by subtract baseline and the trial mean\n",
    "            seg_after = butter_bandpass_filter((seg.T - bsl - trial_mean).T, lowcut=lowcut, highcut=highcut, fs=sr)\n",
    "            if np.isnan(seg_after).sum()==0:\n",
    "                data.append(seg_after)\n",
    "                labels.append(mi_events.Description[j])\n",
    "    return data, labels\n",
    "\n",
    "def reshape_data(data, label):\n",
    "    \"\"\"\n",
    "    reshape the data to the shape: n_samples * time * channels\n",
    "    binarize the labels for the model\n",
    "    \"\"\"\n",
    "    x = np.dstack(data)\n",
    "    x = x.reshape(x.shape[2], x.shape[1], x.shape[0])\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    y = lb.fit_transform(label)\n",
    "    return x, y\n",
    "\n",
    "def create_model(filters=256, pool_size=4, units=64, dropout=0.1, optim='adam'):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(filters=filters, kernel_size=5, activation = 'relu', input_shape = (750, 3)))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high pass + ICA (remove EOG) + CSP (augmentation)+ 1DConv(feature extraction) + LSTM (sequential learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data after band-pass filter\n",
    "train_data, train_label = populate_filt_data(train_files, event_start, event_end, bsl_start, bsl_end)\n",
    "data, label = reshape_data(train_data, train_label)\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# TODO: Skip ICA for now because it didn't work\n",
    "\n",
    "# CSP transformation\n",
    "csp = CSP(rank={'eeg':3}, transform_into = 'csp_space')\n",
    "x_new = csp.fit_transform(train_x.reshape(train_x.shape[0], train_x.shape[2], train_x.shape[1]), \n",
    "                          np.squeeze(train_y)).reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2])\n",
    "x_new_test = csp.fit_transform(test_x.reshape(test_x.shape[0], test_x.shape[2], test_x.shape[1]),\n",
    "                               np.squeeze(test_y)).reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2])\n",
    "\n",
    "# plot top CSP filters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 28s 716ms/step - loss: 0.6941 - accuracy: 0.5436\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 26s 711ms/step - loss: 0.6925 - accuracy: 0.5205\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 25s 684ms/step - loss: 0.6849 - accuracy: 0.5338\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 25s 703ms/step - loss: 0.6772 - accuracy: 0.5660\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 27s 743ms/step - loss: 0.6697 - accuracy: 0.5971\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 25s 694ms/step - loss: 0.6677 - accuracy: 0.5907\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 25s 688ms/step - loss: 0.6520 - accuracy: 0.6202\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 25s 688ms/step - loss: 0.6626 - accuracy: 0.6026\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 25s 686ms/step - loss: 0.6429 - accuracy: 0.6113\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 25s 688ms/step - loss: 0.6296 - accuracy: 0.6546\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 25s 691ms/step - loss: 0.6330 - accuracy: 0.6377\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 25s 689ms/step - loss: 0.6308 - accuracy: 0.6566\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 25s 688ms/step - loss: 0.6127 - accuracy: 0.6560\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 25s 698ms/step - loss: 0.5983 - accuracy: 0.6739\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 25s 684ms/step - loss: 0.5783 - accuracy: 0.7030\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 25s 681ms/step - loss: 0.5765 - accuracy: 0.6883\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 25s 686ms/step - loss: 0.5462 - accuracy: 0.7267\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 25s 691ms/step - loss: 0.5180 - accuracy: 0.7462\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 25s 693ms/step - loss: 0.5161 - accuracy: 0.7444\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 25s 694ms/step - loss: 0.5009 - accuracy: 0.7498\n",
      "14/14 [==============================] - 2s 131ms/step - loss: 0.8942 - accuracy: 0.5056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8942028880119324, 0.5055928230285645]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model here\n",
    "model = create_model()\n",
    "model.fit(x_new, train_y, epochs=20, batch_size=50)\n",
    "model.evaluate(x_new_test, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffe2ecd74d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(33.0, 0.5, 'Predicted'), Text(0.5, 15.0, 'Actual')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_new_test)\n",
    "cm = confusion_matrix(test_y, np.rint(y_pred))\n",
    "ax = sn.heatmap(cm, annot=True, fmt='d', cbar=False, xticklabels=['Left', 'Right'], yticklabels=['Left', 'Right'])\n",
    "ax.set(xlabel='Actual', ylabel='Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.51      0.52       235\n",
      "           1       0.48      0.50      0.49       212\n",
      "\n",
      "    accuracy                           0.51       447\n",
      "   macro avg       0.51      0.51      0.51       447\n",
      "weighted avg       0.51      0.51      0.51       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, np.rint(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on each individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline(train_data, train_label, verbose=1):\n",
    "    data, label = reshape_data(train_data, train_label)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, label, test_size=0.3, random_state=42)\n",
    "\n",
    "    # TODO: Skip ICA for now because it didn't work\n",
    "\n",
    "    # CSP transformation\n",
    "    csp = CSP(rank={'eeg':3}, transform_into = 'csp_space')\n",
    "    x_new = csp.fit_transform(train_x.reshape(train_x.shape[0], train_x.shape[2], train_x.shape[1]), \n",
    "                              np.squeeze(train_y)).reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2])\n",
    "    x_new_test = csp.fit_transform(test_x.reshape(test_x.shape[0], test_x.shape[2], test_x.shape[1]),\n",
    "                                   np.squeeze(test_y)).reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2])\n",
    "    model = create_model()\n",
    "    model.fit(x_new, train_y, epochs=10, batch_size=20, verbose=verbose)\n",
    "    y_pred = model.predict_classes(x_new_test)\n",
    "    eval_result = classification_report(test_y, np.rint(y_pred), output_dict=True)\n",
    "    return eval_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 1/9 [00:45<06:02, 45.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 2/9 [01:30<05:16, 45.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 3/9 [02:15<04:31, 45.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #3\n",
      "WARNING:tensorflow:5 out of the last 24 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffe2ece09e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 4/9 [02:53<03:35, 43.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #4\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffe3384a830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 5/9 [03:42<02:59, 44.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #5\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffe364d7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 6/9 [04:27<02:14, 44.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #6\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffe7a069f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 7/9 [05:12<01:29, 44.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #7\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffe2edf13b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 8/9 [06:03<00:46, 46.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #8\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffe34876560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:48<00:00, 45.43s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "mne.set_log_level('warning')\n",
    "for i in tqdm(range(int(len(train_files)/2))):\n",
    "    print('Training sample #%d'%i)\n",
    "    indiv_train = [train_files[i*2], train_files[i*2+1]]\n",
    "    train_data, train_label = populate_filt_data(indiv_train, event_start, event_end, bsl_start, bsl_end)\n",
    "    eval_result = training_pipeline(train_data, train_label, verbose=0)\n",
    "    results.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': {'precision': 0.5833333333333334,\n",
       "   'recall': 0.34146341463414637,\n",
       "   'f1-score': 0.43076923076923085,\n",
       "   'support': 41},\n",
       "  '1': {'precision': 0.4375,\n",
       "   'recall': 0.6774193548387096,\n",
       "   'f1-score': 0.5316455696202531,\n",
       "   'support': 31},\n",
       "  'accuracy': 0.4861111111111111,\n",
       "  'macro avg': {'precision': 0.5104166666666667,\n",
       "   'recall': 0.509441384736428,\n",
       "   'f1-score': 0.48120740019474195,\n",
       "   'support': 72},\n",
       "  'weighted avg': {'precision': 0.5205439814814815,\n",
       "   'recall': 0.4861111111111111,\n",
       "   'f1-score': 0.4742020988856432,\n",
       "   'support': 72}},\n",
       " {'0': {'precision': 0.5757575757575758,\n",
       "   'recall': 0.5,\n",
       "   'f1-score': 0.5352112676056339,\n",
       "   'support': 38},\n",
       "  '1': {'precision': 0.5128205128205128,\n",
       "   'recall': 0.5882352941176471,\n",
       "   'f1-score': 0.547945205479452,\n",
       "   'support': 34},\n",
       "  'accuracy': 0.5416666666666666,\n",
       "  'macro avg': {'precision': 0.5442890442890442,\n",
       "   'recall': 0.5441176470588236,\n",
       "   'f1-score': 0.541578236542543,\n",
       "   'support': 72},\n",
       "  'weighted avg': {'precision': 0.546037296037296,\n",
       "   'recall': 0.5416666666666666,\n",
       "   'f1-score': 0.541224516046048,\n",
       "   'support': 72}},\n",
       " {'0': {'precision': 0.475,\n",
       "   'recall': 0.5588235294117647,\n",
       "   'f1-score': 0.5135135135135136,\n",
       "   'support': 34},\n",
       "  '1': {'precision': 0.53125,\n",
       "   'recall': 0.4473684210526316,\n",
       "   'f1-score': 0.4857142857142857,\n",
       "   'support': 38},\n",
       "  'accuracy': 0.5,\n",
       "  'macro avg': {'precision': 0.503125,\n",
       "   'recall': 0.5030959752321982,\n",
       "   'f1-score': 0.4996138996138997,\n",
       "   'support': 72},\n",
       "  'weighted avg': {'precision': 0.5046875,\n",
       "   'recall': 0.5,\n",
       "   'f1-score': 0.49884169884169893,\n",
       "   'support': 72}},\n",
       " {'0': {'precision': 0.5106382978723404,\n",
       "   'recall': 0.631578947368421,\n",
       "   'f1-score': 0.5647058823529411,\n",
       "   'support': 38},\n",
       "  '1': {'precision': 0.5483870967741935,\n",
       "   'recall': 0.425,\n",
       "   'f1-score': 0.47887323943661964,\n",
       "   'support': 40},\n",
       "  'accuracy': 0.5256410256410257,\n",
       "  'macro avg': {'precision': 0.5295126973232669,\n",
       "   'recall': 0.5282894736842105,\n",
       "   'f1-score': 0.5217895608947803,\n",
       "   'support': 78},\n",
       "  'weighted avg': {'precision': 0.5299966562835471,\n",
       "   'recall': 0.5256410256410257,\n",
       "   'f1-score': 0.5206891423958532,\n",
       "   'support': 78}},\n",
       " {'0': {'precision': 0.47619047619047616,\n",
       "   'recall': 0.5555555555555556,\n",
       "   'f1-score': 0.5128205128205129,\n",
       "   'support': 36},\n",
       "  '1': {'precision': 0.5555555555555556,\n",
       "   'recall': 0.47619047619047616,\n",
       "   'f1-score': 0.5128205128205129,\n",
       "   'support': 42},\n",
       "  'accuracy': 0.5128205128205128,\n",
       "  'macro avg': {'precision': 0.5158730158730158,\n",
       "   'recall': 0.5158730158730158,\n",
       "   'f1-score': 0.5128205128205129,\n",
       "   'support': 78},\n",
       "  'weighted avg': {'precision': 0.518925518925519,\n",
       "   'recall': 0.5128205128205128,\n",
       "   'f1-score': 0.5128205128205128,\n",
       "   'support': 78}},\n",
       " {'0': {'precision': 0.5,\n",
       "   'recall': 0.5714285714285714,\n",
       "   'f1-score': 0.5333333333333333,\n",
       "   'support': 35},\n",
       "  '1': {'precision': 0.53125,\n",
       "   'recall': 0.4594594594594595,\n",
       "   'f1-score': 0.4927536231884059,\n",
       "   'support': 37},\n",
       "  'accuracy': 0.5138888888888888,\n",
       "  'macro avg': {'precision': 0.515625,\n",
       "   'recall': 0.5154440154440154,\n",
       "   'f1-score': 0.5130434782608696,\n",
       "   'support': 72},\n",
       "  'weighted avg': {'precision': 0.5160590277777778,\n",
       "   'recall': 0.5138888888888888,\n",
       "   'f1-score': 0.5124798711755234,\n",
       "   'support': 72}},\n",
       " {'0': {'precision': 0.6086956521739131,\n",
       "   'recall': 0.358974358974359,\n",
       "   'f1-score': 0.45161290322580644,\n",
       "   'support': 39},\n",
       "  '1': {'precision': 0.4897959183673469,\n",
       "   'recall': 0.7272727272727273,\n",
       "   'f1-score': 0.5853658536585367,\n",
       "   'support': 33},\n",
       "  'accuracy': 0.5277777777777778,\n",
       "  'macro avg': {'precision': 0.5492457852706301,\n",
       "   'recall': 0.5431235431235432,\n",
       "   'f1-score': 0.5184893784421716,\n",
       "   'support': 72},\n",
       "  'weighted avg': {'precision': 0.5541999408459035,\n",
       "   'recall': 0.5277777777777778,\n",
       "   'f1-score': 0.5129163388408079,\n",
       "   'support': 72}},\n",
       " {'0': {'precision': 0.48484848484848486,\n",
       "   'recall': 0.37209302325581395,\n",
       "   'f1-score': 0.4210526315789474,\n",
       "   'support': 43},\n",
       "  '1': {'precision': 0.47058823529411764,\n",
       "   'recall': 0.5853658536585366,\n",
       "   'f1-score': 0.5217391304347826,\n",
       "   'support': 41},\n",
       "  'accuracy': 0.47619047619047616,\n",
       "  'macro avg': {'precision': 0.47771836007130125,\n",
       "   'recall': 0.47872943845717525,\n",
       "   'f1-score': 0.471395881006865,\n",
       "   'support': 84},\n",
       "  'weighted avg': {'precision': 0.47788812494694843,\n",
       "   'recall': 0.47619047619047616,\n",
       "   'f1-score': 0.4701972322109622,\n",
       "   'support': 84}},\n",
       " {'0': {'precision': 0.42105263157894735,\n",
       "   'recall': 0.47058823529411764,\n",
       "   'f1-score': 0.4444444444444444,\n",
       "   'support': 34},\n",
       "  '1': {'precision': 0.47058823529411764,\n",
       "   'recall': 0.42105263157894735,\n",
       "   'f1-score': 0.4444444444444444,\n",
       "   'support': 38},\n",
       "  'accuracy': 0.4444444444444444,\n",
       "  'macro avg': {'precision': 0.4458204334365325,\n",
       "   'recall': 0.4458204334365325,\n",
       "   'f1-score': 0.4444444444444444,\n",
       "   'support': 72},\n",
       "  'weighted avg': {'precision': 0.4471964224286206,\n",
       "   'recall': 0.4444444444444444,\n",
       "   'f1-score': 0.4444444444444444,\n",
       "   'support': 72}}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_precision_lstm = [x['weighted avg']['precision'] for x in results]\n",
    "all_avg_recall_lstm = [x['weighted avg']['recall'] for x in results]\n",
    "all_accuracy_lstm = [x['accuracy']for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4861111111111111,\n",
       " 0.5416666666666666,\n",
       " 0.5,\n",
       " 0.5256410256410257,\n",
       " 0.5128205128205128,\n",
       " 0.5138888888888888,\n",
       " 0.5277777777777778,\n",
       " 0.47619047619047616,\n",
       " 0.4444444444444444]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accuracy_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean precision = 0.512837\n",
      "mean recall = 0.503171\n",
      "mean accuracy = 0.503171\n"
     ]
    }
   ],
   "source": [
    "print('mean precision = %f'%np.mean(all_avg_precision_lstm))\n",
    "print('mean recall = %f'%np.mean(all_avg_recall_lstm))\n",
    "print('mean accuracy = %f'%np.mean(all_accuracy_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std precision = 0.031289\n",
      "std recall = 0.028437\n",
      "std accuracy = 0.028437\n"
     ]
    }
   ],
   "source": [
    "print('std precision = %f'%np.std(all_avg_precision_lstm))\n",
    "print('std recall = %f'%np.std(all_avg_recall_lstm))\n",
    "print('std accuracy = %f'%np.std(all_accuracy_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSP-LDA baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4988814317673378"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_label = populate_filt_data(train_files, event_start, event_end, bsl_start, bsl_end)\n",
    "data, label = reshape_data(train_data, train_label)\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "csp = CSP(n_components=4, rank={'eeg':3})\n",
    "x_new = csp.fit_transform(train_x.reshape(train_x.shape[0], train_x.shape[2], train_x.shape[1]), \n",
    "                          np.squeeze(train_y))\n",
    "x_new_test = csp.fit_transform(test_x.reshape(test_x.shape[0], test_x.shape[2], test_x.shape[1]),\n",
    "                               np.squeeze(test_y))\n",
    "lda = LinearDiscriminantAnalysis(solver = 'lsqr')\n",
    "lda.fit(x_new, train_y)\n",
    "lda.score(x_new_test, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(33.0, 0.5, 'Predicted'), Text(0.5, 15.0, 'Actual')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = lda.predict(x_new_test)\n",
    "cm = confusion_matrix(test_y, np.rint(y_pred))\n",
    "ax = sn.heatmap(cm, annot=True, fmt='d', cbar=False, xticklabels=['Left', 'Right'], yticklabels=['Left', 'Right'])\n",
    "ax.set(xlabel='Actual', ylabel='Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.31      0.39       235\n",
      "           1       0.48      0.71      0.57       212\n",
      "\n",
      "    accuracy                           0.50       447\n",
      "   macro avg       0.51      0.51      0.48       447\n",
      "weighted avg       0.51      0.50      0.48       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, np.rint(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On each individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csp_lda_pipeline(train_data, train_label):\n",
    "    data, label = reshape_data(train_data, train_label)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, label, test_size=0.3, random_state=42)\n",
    "\n",
    "    csp = CSP(n_components=4, rank={'eeg':3})\n",
    "    x_new = csp.fit_transform(train_x.reshape(train_x.shape[0], train_x.shape[2], train_x.shape[1]), \n",
    "                              np.squeeze(train_y))\n",
    "    x_new_test = csp.fit_transform(test_x.reshape(test_x.shape[0], test_x.shape[2], test_x.shape[1]),\n",
    "                                   np.squeeze(test_y))\n",
    "    lda = LinearDiscriminantAnalysis(solver = 'lsqr')\n",
    "    lda.fit(x_new, train_y)\n",
    "    print(lda.score(x_new_test, test_y))\n",
    "\n",
    "    y_pred = lda.predict(x_new_test)\n",
    "    eval_result = classification_report(test_y, np.rint(y_pred), output_dict=True)\n",
    "    return eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\r",
      " 11%|█         | 1/9 [00:00<00:07,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4444444444444444\n",
      "Training sample #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\r",
      " 22%|██▏       | 2/9 [00:01<00:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5277777777777778\n",
      "Training sample #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\r",
      " 33%|███▎      | 3/9 [00:02<00:05,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4722222222222222\n",
      "Training sample #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\r",
      " 44%|████▍     | 4/9 [00:03<00:04,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5769230769230769\n",
      "Training sample #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\r",
      " 56%|█████▌    | 5/9 [00:04<00:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41025641025641024\n",
      "Training sample #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\r",
      " 67%|██████▋   | 6/9 [00:05<00:02,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "Training sample #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\r",
      " 78%|███████▊  | 7/9 [00:06<00:01,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4027777777777778\n",
      "Training sample #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\r",
      " 89%|████████▉ | 8/9 [00:08<00:01,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5476190476190477\n",
      "Training sample #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuanyuwu/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "100%|██████████| 9/9 [00:08<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "mne.set_log_level('warning')\n",
    "for i in tqdm(range(int(len(train_files)/2))):\n",
    "    print('Training sample #%d'%i)\n",
    "    train_data, train_label = populate_filt_data([train_files[i*2], train_files[i*2+1]], event_start, event_end, bsl_start, bsl_end)\n",
    "    eval_result = csp_lda_pipeline(train_data, train_label)\n",
    "    results.append(eval_result)\n",
    "all_avg_precision_lda = [x['weighted avg']['precision'] for x in results]\n",
    "all_avg_recall_lda = [x['weighted avg']['recall'] for x in results]\n",
    "all_accuracy_lda = [x['accuracy']for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean precision = 0.494200\n",
      "mean recall = 0.486891\n",
      "mean accuracy = 0.486891\n"
     ]
    }
   ],
   "source": [
    "print('mean precision = %f'%np.mean(all_avg_precision_lda))\n",
    "print('mean recall = %f'%np.mean(all_avg_recall_lda))\n",
    "print('mean accuracy = %f'%np.mean(all_accuracy_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std precision = 0.067056\n",
      "std recall = 0.068850\n",
      "std accuracy = 0.068850\n"
     ]
    }
   ],
   "source": [
    "print('std precision = %f'%np.std(all_avg_precision_lda))\n",
    "print('std recall = %f'%np.std(all_avg_recall_lda))\n",
    "print('std accuracy = %f'%np.std(all_accuracy_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our model</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.402778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Our model       LDA\n",
       "Subject ID                     \n",
       "0            0.486111  0.444444\n",
       "1            0.541667  0.527778\n",
       "2            0.500000  0.472222\n",
       "3            0.525641  0.576923\n",
       "4            0.512821  0.410256\n",
       "5            0.513889  0.416667\n",
       "6            0.527778  0.402778\n",
       "7            0.476190  0.547619\n",
       "8            0.444444  0.583333"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indiv_accuracy = pd.DataFrame( {'Our model': all_accuracy_lstm, 'LDA':all_accuracy_lda})\n",
    "indiv_accuracy.index.name = 'Subject ID'\n",
    "indiv_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions for check point 1\n",
    "\n",
    "1. Remove EOG artifact: Needed? How?\n",
    "    \n",
    "2. Another tangent: feasible to include EOG information in the classification? Individual variation too high?\n",
    "    \n",
    "3. CSP? Restricted by the number of channels?\n",
    "    \n",
    "4. Difference not distinct between averaged signals\n",
    "    \n",
    "5. Amplitude much smaller after averaging, also noisier\n",
    "    \n",
    "6. preprocesing data: does order matter (DC offset -> filtfilt -> baseline correct); what else needed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute C3-C4, C4-C3, or diff with Cz, then bandpass 7-30Hz\n",
    "take the log of the power (normally distributed)\n",
    "\n",
    "diff more distinct in freq space\n",
    "\n",
    "EOG artifact:\n",
    "\n",
    "ICA (http://www.cogsci.ucsd.edu/academicPubs/igorodni/eog-filtering.pdf)\n",
    "\n",
    "subtract EOG from EEG? **find code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for check point 2\n",
    "\n",
    "1. accuracy not good... problem with approach?\n",
    "2. data augmentation? \n",
    "    \n",
    "    \"deep convolutional generative adversarial network (DCGAN) provided better augmentation performance than traditional DA methods: geometric transformation (GT), autoencoder (AE), and variational autoencoder (VAE)\"\n",
    "    \n",
    "    Is CSP a kind of data augmentation? no, but generate better features\n",
    "    \n",
    "    Worth trying? time domain: high pass + ICA (remove EOG) + CSP (augmentation)+ 1DConv + max pooling (feature extraction) + LSTM (sequential learning)\n",
    "    \n",
    "    try CSP with top 3 filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try on 64 channel set\n",
    "\n",
    "Run model only on EOG to make sure the model is not using eye moving data\n",
    "\n",
    "Try train on individual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
